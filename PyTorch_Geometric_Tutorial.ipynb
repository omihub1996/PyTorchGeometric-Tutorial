{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Geometricで理解するGraph Convolutional Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[公式ドキュメント](https://pytorch-geometric.readthedocs.io/en/latest/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. インストール\n",
    "1. PyTorchのバージョンが1.2.0以上\n",
    "2. torch-geometricおよび依存関係のあるパッケージをインストール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -c \"import torch; print(torch.__version__)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --verbose --no-cache-dir torch-scatter\n",
    "! pip install --verbose --no-cache-dir torch-sparse\n",
    "! pip install --verbose --no-cache-dir torch-cluster\n",
    "! pip install --verbose --no-cache-dir torch-spline-conv (optional)\n",
    "! pip install torch-geometric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. チュートリアルやってみた"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 グラフデータを扱ってみる\n",
    "グラフは何かのもの同士の関係を表すのに使われるが、ものをノード、関係を表す線をエッジと呼ぶ。PyTorch Geometricではこのグラフデータは　```torch_geometric.data.Data``` で保持される。メソッドは代表的なものだけ紹介する。\n",
    "\n",
    "* ```data.x```: ノードの特徴量行列。形状は```[ノード数, ノードの特徴量数]```\n",
    "* ```data.edge_index```: COO形式のエッジ情報。形状は```[2, エッジ数]```\n",
    "* ```data.edge_attr```: エッジの特徴量行列。形状は```[エッジ数, エッジの特徴量数]```\n",
    "* ```data.y```: ターゲット。ノードラベルやグラフラベル。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# ノード情報\n",
    "# 3つのノード(インデックス0,1,2)があり、各ノードが特徴量-1, 0, 1をもつ。\n",
    "# 形状: [ノード数, ノードの特徴量数] = [3, 1]\n",
    "x = torch.tensor([[-1], [0], [1]],dtype=torch.float)\n",
    "\n",
    "# エッジ情報\n",
    "# ノード0と1が双方向で繋がっており、ノード1と2も双方向で繋がっていることを示している。\n",
    "# 形状: [2, エッジ数] = [2, 4]\n",
    "edge_index = torch.tensor(\n",
    "    [[0, 1, 1, 2],\n",
    "     [1, 0, 2, 1]], dtype=torch.long)\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 代表的なデータセット\n",
    "CoraやCiteseer, Pubmed, QM7, FAUSTなど代表的なデータセットを備え持つ。\n",
    "ここでは酵素のENZYMESデータセットロードしてみる。\n",
    "以下のコードから、ENZYMESには6種類のグラフが600個あることがわかる。\n",
    "そのうちの初めのグラフは、37個のノードと168個のエッジを持つことがわかる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "dataset = TUDataset(root='/tmp/ENZYMES', name='ENZYMES')\n",
    "print(\"グラフの数: \", len(dataset))\n",
    "print(\"クラスの数:\",dataset.num_classes)\n",
    "print(\"ノードの特徴量の数: \", dataset.num_node_features)\n",
    "print(\"1つめのグラフ: \", dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "シャッフルも容易にできる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.shuffle()\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "論文引用ネットワークのCoraデータセットも同様にダウンロードしてみる。(ノード(=論文)の分類問題用データセット)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
    "print(\"グラフの数: \", len(dataset))\n",
    "print(\"クラスの数: \", dataset.num_classes)\n",
    "print(\"ノードの特徴量の数: \", dataset.num_node_features)\n",
    "print(\"グラフ情報: \", dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここで```Data```オブジェクトはENZYMESの時に加えて以下の3つの特性も持っている。\n",
    "\n",
    "* ```train_mask``` : 訓練用ノードを示すマスク\n",
    "* ```val_mask```: 評価用ノードを示すマスク\n",
    "* ```test_mask```: テスト用ノードを示すマスク"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 ミニバッチ\n",
    "通常ニューラルネットワークは[ミニバッチで学習する](https://qiita.com/omiita/items/1735c1d048fe5f611f80#4-%E3%83%9F%E3%83%8B%E3%83%90%E3%83%83%E3%83%81%E5%AD%A6%E7%BF%92sgd)ので、ここでPyTorch Geometricによるミニバッチの生成方法を見る。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_scatter import scatter_mean\n",
    "\n",
    "dataset = TUDataset(root='/tmp/ENZYMES', name='ENZYMES', use_node_attr=True)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "for batch in loader:\n",
    "    print(\"ミニバッチの情報: \", batch)\n",
    "    print(\"ミニバッチ内のグラフの種類数: \", batch.num_graphs)\n",
    "    x = scatter_mean(batch.x, batch.batch, dim=0)\n",
    "    print(\"ミニバッチ内のグラフの種類ごとに平均値をとったときの形状: \", x.size())\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 データ加工\n",
    "PyTorchで画像加工をするときは```torchvision```を使うのが通常のやり方であるが、PyTorch Geometricでは独自の加工メソッドを持つ。\n",
    " ```Data```オブジェクトを入力とし、加工後の```Data```オブジェクトを出力とする。\n",
    " ```torch_geometric.transforms.Compose```によって複数の処理を一緒くたにすることができる。\n",
    " \n",
    " 例として3次元画像のデータセットShapeNetを使う。\n",
    "```pre_transform```にはデータセットをディスク上に保存する前に適用する加工を定義する。今回はk-近傍法でグラフを作っている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import ShapeNet\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "dataset = ShapeNet(root='/tmp/ShapeNet', categories=['Airplane'],\n",
    "                   pre_transform=T.KNNGraph(k=6),\n",
    "                  transform=T.RandomTranslate(0.01)) #各ノードの位置をランダムで少しだけずらす。\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Graph Convolutional Networks\n",
    "いよいよGCNを使ってみる。Coraデータセットを使用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.1 データセット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.2 モデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "    \n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.3 学習\n",
    "学習の時の手順は以下の5つをエポック回だけ繰り返す。\n",
    "\n",
    "1. optimizerの勾配初期化\n",
    "2. モデルからの予測値を得る\n",
    "3. 予測値と正解値で損失をとる\n",
    "4. 損失のパックプロップ\n",
    "5. optimizerによるパラメータ更新\n",
    "\n",
    "つまり、\n",
    "1. **勾配初期化**\n",
    "2. **予測値**\n",
    "3. **損失**\n",
    "4. **バックプロップ**\n",
    "5. **更新**\n",
    "\n",
    "で、コードで書けば、\n",
    "1. ```optimizer.zero_grad()```\n",
    "2. ```output=model(input)```\n",
    "3. ```loss=Loss(output, target)```\n",
    "4. ```loss.backward()```\n",
    "5. ```optimizer.step()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net().to(device)\n",
    "data = dataset[0].to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "model.train() #モデルを訓練モードにする。\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.4 評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval() #モデルを評価モードにする。\n",
    "_, pred = model(data).max(dim=1)\n",
    "correct = float(pred[data.test_mask].eq(data.y[data.test_mask]).sum().item())\n",
    "acc = correct / data.test_mask.sum().item()\n",
    "print('Acc: {:.4f}' .format(acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
